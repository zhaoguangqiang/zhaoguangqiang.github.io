---
layout:	post
title:	"install k8s"
date:	2019-08-24
tags:	["kubernetes"]
image:	""
---

# 源:
|  global              | proxy in China    | format                                               |                                   example                                          |
| --------             | :---------------: | :--------------------------------------------------: | :-------------------------------------------------------------------------------:  |
| dockerhub (docker.io)| dockerhub.azk8s.cn| dockerhub.azk8s.cn/<repo-name>/<image-name>:<version>| dockerhub.azk8s.cn/microsoft/azure-cli:2.0.61 dockerhub.azk8s.cn/library/nginx:1.15|
| gcr.io               | gcr.azk8s.cn      | gcr.azk8s.cn/<repo-name>/<image-name>:<version>      | gcr.azk8s.cn/google_containers/hyperkube-amd64:v1.13.5                             |
| quay.io              | quay.azk8s.cn     | quay.azk8s.cn/<repo-name>/<image-name>:<version>     | quay.azk8s.cn/deis/go-dev:v1.10.0                                                  |


install k8s
===

Preparatory Work
---
## master/node节点都需要执行该操作

### install software
```shell
curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
sudo apt update
* The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6A030B21BA07F4FB
* You should check you PUBKEY
* sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys YOUR_KEY
* sudo apt-key adv --keyserver keyserver.ubuntu.com YOUR_KEY
sudo vim /etc/apt/sources.list
add:
  deb http://mirrors.ustc.edu.cn/kubernetes/apt kubernetes-xenial main

sudo apt install docker.io kubeadm kubectl kubelet
sudo usermod -aG docker USERNAME
sudo systemctl start docker kubelet
sudo systemctl enable docker kubelet

//避免/etc/resolv.conf中写入127.0.0.1,导致coreDns无法正常工作,请优先修改以下而配置
sudo sed -e 's/^dns=dnsmasq/#dns=dnsmasq/g' -i /etc/NetworkManager/NetworkManager.conf
sudo reboot
```



install Master
---
#### prepare kubernetes plugin docker
```shell
#!/bin/bash
images=(
  kube-apiserver:v1.15.3
  kube-controller-manager:v1.15.3
  kube-scheduler:v1.15.3
  kube-proxy:v1.15.3
  
  pause:3.1
  etcd:3.3.10
  coredns:1.3.1

  kubernetes-dashboard-amd64:v1.10.0 #界面组件
  metrics-server-amd64:v0.3.3  #扩容组件

  nginx-ingress-controller:0.25.0 #ingress-nginx反向代理插件
)

for imageName in ${images[@]} ; do
  docker pull gcr.azk8s.cn/google_containers/$imageName
  docker tag gcr.azk8s.cn/google_containers/$imageName k8s.gcr.io/$imageName
  docker rmi gcr.azk8s.cn/google_containers/$imageName
done


quay_images=(
  nginx-ingress-controller:0.25.1
)

for imageName in ${quay_images[@]} ; do
  docker pull quay.azk8s.cn/kubernetes-ingress-controller/$imageName
  docker tag  quay.azk8s.cn/kubernetes-ingress-controller/$imageName quay.io/kubernetes-ingress-controller/$imageName
  docker rmi  quay.azk8s.cn/kubernetes-ingress-controller/$imageName
done

```

#### install service

```shell
//如果存在swap,请关闭swap
swapoff -a
//初始化服务
sudo kubeadm init --kubernetes-version=KUBE_VERSION --apiserver-advertise-address=CURRENT_MASTER_IP --pod-network-cidr=10.244.0.0/16
//拷贝admin.conf,使当前用户具备使用kubeadm,kubectl的权限
sudo cp /etc/kubernetes/admin.conf ~/.kube/config
```

#### install network

* wget http://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
* 替换image源quay.io -> quay.azk8s.cn
* kubectl apply -f kube-flannel.yml

注:calico存在问题,不建议使用

#### 以下操作注意事项

* 安装过程中，ingress/metric需要放置到master节点上，master节点下载ingress镜像，但是可能会分配至node节点，出现无法找到image的情况
  
* 默认master节点是不会运行pod，在执行完部署前需要允许master当负载节点使用, 否则该pod状态会为pending,无法提供服务

* 支持Deployment在master节点部署

```
//获取master label和value
kubectl get nodes --show-labels

//为Deployment.spec.template.spec加入以下内容,保证可以在master节点上创建
//支持master的容忍
nodeSelector:
  MASTER_LABEL: MASTER_VALUE
tolerations:
- key: "node-role.kubernetes.io/master"
  operator: "Equal"
  value: ""
  effect: "NoSchedule"
```


#### install ingress

* 下载ingress-nginx镜像

  详情参见 "prepare kubernetes plugin docker"

* 向mandatory中的ingress-nginx-controller的中Deployment.spec.template.spec中添加以下内容,来暴露服务

```yaml
  hostNetwork: true
```

* 部署ingress-nginx

```shell
git clone https://github.com/kubernetes/ingress-nginx.git
kubectl apply -f deploy/static/mandatory.yaml
```

* 如果需要使用HTTPS,请按照以下步骤生成相关证书密钥:

```shell
//生成证书
openssl req -x509 -new -nodes -key ca-key.pem -days 10000 -out ncserver-ca.crt -subj "/CN=ncserver-ca"
kubectl create secret tls ingress-secret --key ca-key.pem  --cert ncserver-ca.crt

//在ingress配置文件中Ingress.spec加入tls支持
tls:
- hosts:
  - k8s.navicore.cn
  secretName: ingress-secret

//应用配置
kubectl apply -f ingress.yaml
```

* ingress-nginx-controller error:请检查80端口是否被占用


#### HPA

* heapster已废弃,请使用metric-server

* 下载metrics-server镜像

*请参考* "prepare kubernetes plugin docker"

* 下载及修改配置
```shell
git clone https://github.com/kubernetes-incubator/metrics-server.git
cd metrics-server
vim deploy/1.8+/metrics-server-deployment.yaml

# 修改ServiceAccount.spec.template.spec.containers.imagePullPolicy, 否则默认是总会从服务端下载
imagePullPolicy : IfNotPresent

# 修改ServiceAccount.spec.template.spec.containers.args
# 否则可能无法获取当前cpu的使用率
args:
- --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP
- --kubelet-insecure-tls
```

* 部署
```shell
kubectl create -f deploy/1.8+/
```

* 查看HPA的状态
```shell
kubectl top node
```

#### Dashboard

* 下载容器,参见 "prepare kubernetes plugin docker"

* 部署:kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml

* 创建admin-role.yaml
```shell
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: admin
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: admin
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin
  namespace: kube-system
  labels:
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
```

* 获取token
```shell
kubectl -n kube-system get secret | grep admin-token
kubectl -n kube-system describe secret ADMIN_TOKEN_NAME
```

#### 检验全部服务状态
* kube-system状态: kubectl get pods -n kube-system -o wide
* ingress-nginx状态: kubectl get pods -n ingress-nginx -o wide


install Node
---

#### prepare kubernetes plugin docker
 ```shell
#!/bin/bash
images=(
  kube-proxy:v1.15.3
  pause:3.1
)

for imageName in ${images[@]} ; do
  docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName
  docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
done
```

#### join to master
```shell
sudo kubeadm join 172.23.127.113:6443 --token atg34o.2nwr0dn6ttojbt4h --discovery-token-ca-cert-hash sha256:3d236eac9a79894db27ed38cef6022e7051c5df54384a3f3d9740ab57fb92e35 

#如果join失败，请在master节点重新生成token与sha256，生成步骤如下:
kubeadm token create
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'
```

#### 创建并使用 ingress-secret
```shell
kubectl create secret tls ingress-secret --key private.key  --cert public.crt
add Ingress.spec.tls.hosts.secretName: ingress-secret in ingress.yaml
```


注:
---

* coreDns处于pending状态

```shell
请修改/etc/resolv.conf避免出现循环
resolvconf -u
```

* dashboard token 不小心被删
```shell
kubectl get secret -n kube-system | grep admin
kubectl describe YOUR_SECRET_NAME -n kube-sytem
```

* 修改kube基础插件配置
```shell
vim /etc/kubernetes/manifests/
```

* 启动/关闭Master作为功能节点

support Node on Master:
```shell
  kubectl taint node --all node-role.kubernetes.io/master-
```
disable support Node on Master:
```shell
  kubectl taint node MASTERNAME node-role.kubernetes.io/master="":NoSchedule
```

* [更新节点名称](https://my.oschina.net/u/3390908/blog/1649764)

升级
===
[了解更多](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade-1-15/)

升级k8s
---

#### 升级master

* 更新kubeadm所在的master

```shell
#查看当前k8s版本
kubeadm config images list

#查看当前可升级的版本
kubeadm upgrade plan

#升级k8s的组件到最新版本
sudo apt install kubeadm

#下载相关docker image,由于墙的原因,本应该在下一步下载的镜像单独分出一步
方法可参见:prepare kubernetes plugin docker

#更新相关组件(api-server, controller, scheduler, proxy, coreDNS, etcd)
kubeadm upgrade apply <VERSION>
```

* 更新其他master节点

```shell
sudo kubeadm upgrade node
```

* 更新kubectl kubelet

```shell
#安装其他组件
sudo apt install kubectl kubelet

#重启kubelet
sudo systemctl restart kubelet
```

升级node
---

* master上隔离清空node

```shell
#隔离node节点(master)
sudo kubeadm cordon <NODE-NAME>

#清空node中的pod(master)
suod kubeadm drain <NODE-NAME> --ignore-daemonsets

#查看当前可升级的版本
sudo kubeadm upgrade node

#升级
sudo apt install kubectl kubelet

#重启
sudo systemctl restart kubelet

#恢复node(master)
sudo kubectl uncordon <NODE-NAME> 
```

查看node
---
```shell
kubectl get nodes
```

备份etcd
===

[etcdctl snapshot1](https://github.com/etcd-io/etcd/tree/master/etcdctl#snapshot-subcommand)
[Backing up an etcd cluster](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster)

install etcdctl
---

```shell
wget https://github.com/etcd-io/etcd/releases/download/v3.4.0/etcd-v3.4.0-linux-amd64.tar.gz
tar xvf etcd-v3.4.0-linux-amd64.tar.gz
cd etcd-v3.4.0-linux-amd64/
sudo cp etcd etcdctl /usr/local/bin/
```

backup etcd
---

```shell
export ETCDCTL_API=3
sudo etcdctl --endpoints=<IP>:2379 --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key --cacert=/etc/kubernetes/pki/etcd/ca.crt snapshot save snapshot.db
```

* 启动etcd backup定时任务
[etcd_backup_cron.yaml]()

restore etcd
---

```shell
docker run --rm -v '/tmp/etcd-snapshot:/backup' -v '/var/lib/etcd:/var/lib/etcd' --env ETCDCTL_API=3 'k8s.gcr.io/etcd:3.3.10' /bin/sh -c "etcdctl snapshot restore '/backup/20190910_153008_snapshot.db'; mv /default.etcd/member/ /var/lib/etcd/"
```

备份master
===

backup master
---

```shell
mkdir backup
sudo cp /etc/kubernetes backup/kubernetes
sudo cp /var/lib/kubelet backup/kubelet
[备份etcd]()
```

restore master
---

```shell
sudo systemctl stop kubelet

[恢复etcd]()
rm /etc/kubernetes
rm /var/lib/kubelet

sudo cp -r backup/kubernetes /etc/kubernetes
sudo cp -r backup/kubelet /var/lib/kubelet

sudo systemctl start kubelet
```
